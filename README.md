# Bias-Aware-AI
PLP Week 7 project Bias Aware AI focuses on designing responsible and fair AI systems. It covers algorithmic bias, GDPR, and ethical principles. Using AI Fairness 360, we audit the COMPAS dataset for racial bias and propose solutions to improve fairness, transparency, and accountability in AI.




✅ Violet
Part 1: Theoretical Understanding

Q1: Algorithmic bias + 2 examples

Q2: Transparency vs Explainability

Q3: GDPR and AI

Principles matching

Save to: part1_theory/


✅ Mike
Part 2: Case Study Analysis

Case 1: Amazon’s biased hiring tool

Case 2: Facial recognition in policing

Bonus Task (Optional): Ethical AI in healthcare guideline

Save to: part2_case_studies/ and bonus_guideline.md


✅ Tshimo
Part 3: Practical Audit

Analyze COMPAS dataset using AI Fairness 360

Generate visualizations (bias in false positive rates)

Write 300-word report with findings and fixes

Part 4: Ethical Reflection

Save to: part3_audit/ and ethical_reflection.md




```
bias-aware-ai/
│
├── README.md                                  # Team effort
│
├── part1_theory/                              # Assigned: Violet
│   ├── violet_algorithmic_bias.md
│   ├── violet_transparency_explainability.md
│   ├── violet_gdpr_and_ai.md
│   └── violet_principles_matching.md
│
├── part2_case_studies/                        # Assigned: Mike
│   ├── mike_case1_amazon_hiring_tool.md
│   └── mike_case2_facial_recognition_policing.md
│
├── part3_audit/                               # Assigned: Tshimo
│   ├── tshimo_compas_audit.ipynb
│   ├── data/
│   │   └── compas-scores-two-years.csv
│   ├── visualizations/
│   │   ├── tshimo_false_positive_rates.png
│   │   └── tshimo_risk_score_distribution.png
│   └── tshimo_audit_report.md
│
├── tshimo_ethical_reflection.md               # Assigned: Tshimo
│
└── mike_bonus_healthcare_ai_guideline.md      # Assigned: Mike (Optional)
```